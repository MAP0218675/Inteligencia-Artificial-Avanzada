{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "820386db",
   "metadata": {},
   "source": [
    "#### IMPORTS Y CONFIGURACIÓN INICIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "4d76545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necesarios para el análisis\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "import time\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d84f7f3",
   "metadata": {},
   "source": [
    "##### Explicación de Imports\n",
    "\n",
    "En este bloque importamos todas las librerías necesarias para el análisis completo del Titanic:\n",
    "\n",
    "- **pandas**: Para manipulación y análisis de datos\n",
    "- **numpy**: Para operaciones numéricas\n",
    "- **seaborn y matplotlib**: Para visualizaciones\n",
    "- **plotly**: Para gráficos interactivos\n",
    "- **sklearn**: Para machine learning (clasificadores, métricas, preprocesamiento)\n",
    "- **PCA**: Para análisis de componentes principales\n",
    "\n",
    "También configuramos el estilo de visualización para que sea consistente en todo el análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7406ff75",
   "metadata": {},
   "source": [
    "#### CARGA DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "57f8e1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de los datasets:\n",
      "Train: (891, 12)\n",
      "Test: (418, 11)\n"
     ]
    }
   ],
   "source": [
    "# Cargar los datasets\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "print(\"Forma de los datasets:\")\n",
    "print(f\"Train: {df.shape}\")\n",
    "print(f\"Test: {test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b389660",
   "metadata": {},
   "source": [
    "##### Explicación de Carga de Datos\n",
    "\n",
    "**Resultados obtenidos:**\n",
    "- **Dataset de entrenamiento (train.csv)**: 891 filas × 12 columnas\n",
    "- **Dataset de prueba (test.csv)**: 418 filas × 11 columnas\n",
    "\n",
    "**Observaciones importantes:**\n",
    "- El dataset de entrenamiento tiene una columna adicional llamada \"Survived\" que es nuestra variable objetivo\n",
    "- El dataset de prueba no tiene la columna \"Survived\" porque es lo que debemos predecir\n",
    "- La diferencia en el número de filas es normal: usamos 891 registros para entrenar y 418 para probar el modelo\n",
    "- Esta distribución es típica en problemas de machine learning (aproximadamente 70% entrenamiento, 30% prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80153265",
   "metadata": {},
   "source": [
    "####  ANÁLISIS INICIAL CON DATOS DE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "1262d5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0b/36rw0ltd0vg3t22nhv3dkq0r0000gn/T/ipykernel_14735/476956727.py:2: FutureWarning:\n",
      "\n",
      "DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Interpolación de datos de test \n",
    "test.interpolate(method=\"spline\", order=3, inplace=True)\n",
    "\n",
    "# Seleccionar datos numéricos del test\n",
    "numeric_data = test.select_dtypes(include=[\"float64\", \"int64\"])\n",
    "numeric_columns = [column for column in numeric_data.columns if column != \"PassengerId\"]\n",
    "numeric_data = numeric_data[numeric_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139685ac",
   "metadata": {},
   "source": [
    "##### Explicación del Análisis Inicial\n",
    "\n",
    "**Proceso realizado:**\n",
    "1. **Interpolación**: Aplicamos interpolación spline de orden 3 al dataset de test para manejar valores faltantes\n",
    "2. **Selección de variables numéricas**: Extraemos solo las columnas con datos numéricos (float64, int64)\n",
    "3. **Exclusión de PassengerId**: Eliminamos esta columna ya que es solo un identificador y no aporta información para el análisis\n",
    "\n",
    "**Propósito:**\n",
    "- Preparar los datos para análisis de correlación y PCA\n",
    "- Manejar valores faltantes de manera suave usando interpolación\n",
    "- Enfocarnos solo en variables numéricas para análisis estadístico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a043827d",
   "metadata": {},
   "source": [
    "#### ANÁLISIS DE CORRELACIÓN CON DATOS DE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "6f08e540",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(24898) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "# Matriz de correlación con datos de test \n",
    "corr_data = numeric_data.corr()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        z=corr_data,\n",
    "        x=numeric_columns,\n",
    "        y=numeric_columns,\n",
    "        text=corr_data.values,\n",
    "        texttemplate=\"%{text:.2f}\",\n",
    "        colorscale=\"RdBu_r\",\n",
    "        textfont=dict(size=14)\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    title_text=\"Matriz de correlación para la base de datos\",\n",
    "    width = 800,\n",
    "    height = 800\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c0d322",
   "metadata": {},
   "source": [
    "##### Explicación de la Matriz de Correlación\n",
    "\n",
    "**Resultados obtenidos:**\n",
    "La matriz de correlación muestra las relaciones entre las 5 variables numéricas: 'Fare', 'Parch', 'SibSp', 'Age' y 'Pclass'.\n",
    "\n",
    "**Correlaciones más importantes identificadas:**\n",
    "\n",
    "**Correlaciones negativas fuertes:**\n",
    "- **Fare vs Pclass (-0.58)**: Correlación negativa fuerte. Esto indica que a medida que la clase del pasajero aumenta (de primera a tercera clase), la tarifa disminuye significativamente.\n",
    "\n",
    "- **Age vs Pclass (-0.37)**: Correlación negativa moderada. Los pasajeros de mayor edad tienden a viajar en clases más altas (primera y segunda clase).\n",
    "\n",
    "**Correlaciones positivas moderadas:**\n",
    "- **Parch vs SibSp (0.31)**: Correlación positiva moderada. Las personas que viajan con más padres/hijos también tienden a viajar con más hermanos/cónyuges.\n",
    "\n",
    "**Correlaciones débiles:**\n",
    "- **Age vs SibSp (-0.05)**: Correlación prácticamente nula\n",
    "- **Age vs Parch (0.02)**: Correlación prácticamente nula\n",
    "- **Fare vs Parch (0.23)**: Correlación positiva débil\n",
    "- **Fare vs SibSp (0.17)**: Correlación positiva débil\n",
    "\n",
    "**Implicaciones para el modelo:**\n",
    "- La fuerte correlación entre Fare y Pclass sugiere que podrían ser variables redundantes\n",
    "- La edad no está fuertemente relacionada con el tamaño de la familia\n",
    "- Las variables Parch y SibSp tienen cierta relación, pero no son completamente redundantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df57cd4",
   "metadata": {},
   "source": [
    "#### MATRIZ DE DISPERSIÓN CON DATOS DE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "8585f556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(24902) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "# Matriz de dispersión \n",
    "fig = make_subplots(cols=len(numeric_columns), rows=len(numeric_columns))\n",
    "\n",
    "for i, value_x in enumerate(numeric_columns):\n",
    "    for j, value_y in enumerate(numeric_columns):\n",
    "        if i == j:\n",
    "            fig.add_trace(\n",
    "                go.Histogram(\n",
    "                    x=test[value_x],\n",
    "                    marker=dict(\n",
    "                        color=\"steelblue\",\n",
    "                        line=dict(color=\"black\", width=1)\n",
    "                    )\n",
    "                ),\n",
    "                row=i + 1,\n",
    "                col=j + 1,\n",
    "            )\n",
    "            fig.update_xaxes(title_text=value_x, row=i + 1, col=j + 1)\n",
    "            fig.update_yaxes(title_text=value_x, row=i + 1, col=j + 1)\n",
    "        else:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=test[value_x],\n",
    "                    y=test[value_y],\n",
    "                    mode=\"markers\",\n",
    "                    marker=dict(color=\"steelblue\")\n",
    "                ),\n",
    "                row=i + 1,\n",
    "                col=j + 1,\n",
    "            )\n",
    "            fig.update_xaxes(title_text=value_x, row=i + 1, col=j + 1)\n",
    "            fig.update_yaxes(title_text=value_y, row=i + 1, col=j + 1)\n",
    "\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.update_layout(\n",
    "    width=1800,\n",
    "    height=1800\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45d1ea4",
   "metadata": {},
   "source": [
    "##### Explicación de la Matriz de Dispersión (Pair Plot)\n",
    "\n",
    "**Resultados obtenidos:**\n",
    "La matriz de dispersión muestra la distribución univariada y las relaciones bivariadas entre las 5 variables numéricas: `Pclass`, `Age`, `SibSp`, `Parch` y `Fare`.\n",
    "\n",
    "**Análisis de las distribuciones unidimensionales (histogramas en diagonal):**\n",
    "\n",
    "**Pclass:**\n",
    "- Distribución desbalanceada con mayoría en clase 3\n",
    "- Clase 1 y 2 tienen menos pasajeros\n",
    "- Refleja la estructura socioeconómica del Titanic\n",
    "\n",
    "**Age:**\n",
    "- Distribución unimodal sesgada a la derecha\n",
    "- Concentración principal entre 20-40 años\n",
    "- Presencia de valores negativos (datos faltantes codificados incorrectamente)\n",
    "- Requiere imputación de datos faltantes\n",
    "\n",
    "**SibSp (hermanos/cónyuges):**\n",
    "- Distribución altamente sesgada\n",
    "- Gran mayoría con valor 0 (viajan solos)\n",
    "- Frecuencia decrece drásticamente con valores mayores\n",
    "\n",
    "**Parch (padres/hijos):**\n",
    "- Patrón similar a SibSp\n",
    "- Mayoría con valor 0\n",
    "- Distribución de cola larga\n",
    "\n",
    "**Fare (tarifa):**\n",
    "- Distribución fuertemente sesgada a la derecha\n",
    "- Mayoría con tarifas bajas\n",
    "- Cola larga hacia tarifas muy altas\n",
    "\n",
    "**Análisis de relaciones bivariadas (scatter plots):**\n",
    "\n",
    "**Relaciones más importantes:**\n",
    "- **Pclass vs Fare**: Relación inversa clara (clase 1 = tarifas altas)\n",
    "- **SibSp vs Parch**: Correlación positiva (familias más grandes)\n",
    "- **Age vs Pclass**: Clase 1-2 tienen mayor rango de edades\n",
    "- **Fare vs variables familiares**: Tendencia positiva débil\n",
    "\n",
    "**Implicaciones para el modelo:**\n",
    "- Necesidad de imputar datos faltantes en Age\n",
    "- Posible normalización/estandarización por sesgo\n",
    "- Considerar interacciones entre variables familiares\n",
    "- La relación Pclass-Fare podría ser redundante"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9b129f",
   "metadata": {},
   "source": [
    "####  PCA CON DATOS DE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "46212f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(24904) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "# PCA con datos de test (código original)\n",
    "numeric_scaled = StandardScaler().fit_transform(numeric_data)\n",
    "\n",
    "# PCA para 95% de varianza\n",
    "pca_95 = PCA(n_components=0.95).fit(numeric_scaled)\n",
    "varianza_exp = pca_95.explained_variance_ratio_\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=list(range(1, len(varianza_exp) + 1)),\n",
    "        y=varianza_exp,\n",
    "        mode=\"lines+markers\",\n",
    "        marker=dict(color=\"orange\")\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        title_text=\"Componentes\",\n",
    "        tickmode=\"array\",\n",
    "        tickvals=list(range(1, len(varianza_exp) + 1))\n",
    "    ),\n",
    "    yaxis_title=\"Porcentaje de varianza\",\n",
    "    title=\"Porcentaje de varianza explicada por componente\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c9a059",
   "metadata": {},
   "source": [
    "##### Explicación del Porcentaje de Varianza Explicada por Componente (PCA)\n",
    "\n",
    "**Resultados obtenidos:**\n",
    "El gráfico muestra el porcentaje de varianza total de los datos que es explicada por cada componente principal (PCA).\n",
    "\n",
    "**Distribución de varianza por componente:**\n",
    "- **Componente 1:** Explica aproximadamente el 36% de la varianza\n",
    "- **Componente 2:** Explica aproximadamente el 27% de la varianza  \n",
    "- **Componente 3:** Explica aproximadamente el 15% de la varianza\n",
    "- **Componente 4:** Explica aproximadamente el 14% de la varianza\n",
    "- **Componente 5:** Explica aproximadamente el 8% de la varianza\n",
    "\n",
    "**Análisis del Scree Plot:**\n",
    "Este gráfico, conocido como \"scree plot\" o \"gráfico de codo\", es fundamental en PCA para determinar el número óptimo de componentes a retener.\n",
    "\n",
    "**Observaciones clave:**\n",
    "- Se observa una caída significativa en el porcentaje de varianza explicada desde el primer componente hasta el tercer componente\n",
    "- Después del tercer componente, la disminución en la varianza explicada se vuelve mucho menos pronunciada\n",
    "- Se forma un \"codo\" o \"punto de inflexión\" alrededor del Componente 3\n",
    "\n",
    "**Implicaciones para el modelo:**\n",
    "- El \"codo\" en el Componente 3 sugiere que los primeros tres componentes principales capturan una parte sustancial de la varianza total\n",
    "- Los componentes posteriores (4 y 5) contribuyen con información marginalmente menor\n",
    "- Para este conjunto de datos, retener 3 componentes principales podría ser un buen equilibrio entre reducción de dimensionalidad y retención de información relevante\n",
    "- Los primeros dos componentes explican más del 60% de la varianza total, lo que indica una buena capacidad de compresión de la información"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba18c7c9",
   "metadata": {},
   "source": [
    "#### VARIANZA ACUMULADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "85e235b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(24906) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "# Varianza acumulada \n",
    "cumsum_var = np.cumsum(varianza_exp)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=list(range(1, len(varianza_exp) + 1)),\n",
    "        y=cumsum_var,\n",
    "        mode=\"lines+markers\",\n",
    "        marker=dict(color=\"deepskyblue\")\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        title_text=\"Componentes\",\n",
    "        tickmode=\"array\",\n",
    "        tickvals=list(range(1, len(varianza_exp) + 1))\n",
    "    ),\n",
    "    yaxis_title=\"Suma acumulada\",\n",
    "    title=\"Suma acumulada para cada componente\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df93bea1",
   "metadata": {},
   "source": [
    "##### Explicación de la Suma Acumulada de Varianza por Componente\n",
    "\n",
    "**Resultados obtenidos:**\n",
    "El gráfico muestra la suma acumulada de la varianza explicada por cada componente principal.\n",
    "\n",
    "**Distribución de varianza acumulada:**\n",
    "- **Componente 1:** Explica aproximadamente el 36% de la varianza total\n",
    "- **Componente 2:** La suma acumulada alcanza alrededor del 63% (36% + 27%)\n",
    "- **Componente 3:** La suma acumulada llega a aproximadamente el 78% (63% + 15%)\n",
    "- **Componente 4:** La suma acumulada se sitúa en torno al 92% (78% + 14%)\n",
    "- **Componente 5:** Con cinco componentes, se explica casi el 100% de la varianza total\n",
    "\n",
    "**Análisis del gráfico:**\n",
    "Este gráfico es crucial para decidir cuántos componentes principales retener en un análisis PCA.\n",
    "\n",
    "**Observaciones importantes:**\n",
    "- Con solo 2 componentes se explica más del 60% de la varianza\n",
    "- Con 3 componentes se alcanza casi el 80% de la varianza\n",
    "- Con 4 componentes se supera el 90% de la varianza\n",
    "- Con 5 componentes se explica prácticamente toda la varianza\n",
    "\n",
    "**Implicaciones para el modelo:**\n",
    "- **Reducción de dimensionalidad efectiva:** Se puede reducir de 5 a 3 variables sin perder mucha información\n",
    "- **Umbral del 95%:** Si queremos retener el 95% de la varianza, necesitaríamos 4 componentes\n",
    "- **Umbral del 80%:** Si aceptamos el 80% de la varianza, solo necesitaríamos 3 componentes\n",
    "- **Eficiencia:** Los primeros 2 componentes ya explican más de la mitad de la variabilidad total\n",
    "- **Compresión de datos:** Se logra una compresión significativa manteniendo la información más relevante"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72764bd0",
   "metadata": {},
   "source": [
    "#### CÍRCULO DE CORRELACIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0c75f2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(24908) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "# Círculo de correlaciones (código original)\n",
    "pca_data = PCA(n_components=0.90).fit(numeric_scaled)\n",
    "lambdas = pca_data.explained_variance_\n",
    "Gammas = pca_data.components_.T\n",
    "R = Gammas[:, :2] * np.sqrt(lambdas[:2])\n",
    "\n",
    "theta = np.linspace(0, 2*np.pi, 400)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.cos(theta),\n",
    "        y=np.sin(theta),\n",
    "        mode=\"lines\",\n",
    "        marker=dict(color=\"red\"),\n",
    "        showlegend=False\n",
    "    )\n",
    ")\n",
    "\n",
    "for index, value in enumerate(list(numeric_columns)):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[R[index, 0]],\n",
    "            y=[R[index, 1]],\n",
    "            mode=\"markers+text\",\n",
    "            text=[value],\n",
    "            textposition=\"top center\",\n",
    "            showlegend=False\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    yaxis=dict(scaleanchor=\"x\", title_text=\"PC2\"),\n",
    "    xaxis=dict(title=\"PC1\"),\n",
    "    title=\"Círculo de correlaciones (PC1 vs PC2)\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "67991c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(24910) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "c = chi2.ppf(0.95, df=2)\n",
    "\n",
    "elipse_data = np.sqrt(c * lambdas[:2]) * np.array([np.cos(theta), np.sin(theta)]).T\n",
    "outliers = np.sum((numeric_scaled @ Gammas[:, :2])**2 / lambdas[:2], axis=1) > c\n",
    "\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x = (numeric_scaled @ Gammas[:, 0]),\n",
    "        y = (numeric_scaled @ Gammas[:, 1]),\n",
    "        mode = \"markers\",\n",
    "        marker = dict(\n",
    "            color = \"steelblue\"\n",
    "        ),\n",
    "        name = \"Inliers\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "\n",
    "        x = (numeric_scaled @ Gammas[:, 0])[outliers],\n",
    "        y = (numeric_scaled @ Gammas[:, 1])[outliers],\n",
    "        mode = \"markers\",\n",
    "        marker = dict(\n",
    "            color=\"orange\"\n",
    "        ),\n",
    "        name = \"Outliers\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "\n",
    "        x = elipse_data[:, 0],\n",
    "        y = elipse_data[:, 1],\n",
    "        mode = \"lines\",\n",
    "        marker = dict(\n",
    "            color=\"red\"\n",
    "        ),\n",
    "        showlegend = False\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title = \"Curva elíptica (PC1 vs PC2)\",\n",
    "    xaxis = dict(\n",
    "        title_text=\"PC1\"\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title_text=\"PC2\"\n",
    "    ),\n",
    "    width = 800,\n",
    "    height = 600\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92371386",
   "metadata": {},
   "source": [
    "##### Explicación del Círculo de Correlaciones (PC1 vs PC2)\n",
    "\n",
    "**Resultados obtenidos:**\n",
    "El gráfico muestra un círculo de correlaciones que visualiza la relación entre las variables originales (`Pclass`, `SibSp`, `Parch`, `Fare`, `Age`) y los dos primeros componentes principales (PC1 y PC2).\n",
    "\n",
    "**Análisis por componente principal:**\n",
    "\n",
    "**PC1 (Eje Horizontal):**\n",
    "- **Fare y Age**: Tienen correlación positiva fuerte con PC1 (lado derecho del eje)\n",
    "- **Pclass**: Tiene correlación negativa fuerte con PC1 (lado izquierdo del eje)\n",
    "- **Interpretación**: PC1 captura una dimensión relacionada con el estatus socioeconómico\n",
    "\n",
    "**PC2 (Eje Vertical):**\n",
    "- **SibSp y Parch**: Tienen correlación positiva fuerte con PC2 (parte superior del eje)\n",
    "- **Pclass**: También muestra correlación positiva con PC2, aunque menos fuerte\n",
    "- **Interpretación**: PC2 representa una dimensión relacionada con el tamaño de la familia\n",
    "\n",
    "**Relaciones entre variables observadas:**\n",
    "- **SibSp y Parch**: Están muy cerca una de la otra y del círculo, indicando fuerte correlación positiva\n",
    "- **Fare y Age**: Se encuentran en el mismo cuadrante (inferior derecho), sugiriendo correlación positiva\n",
    "- **Pclass**: Ubicado en cuadrante superior izquierdo, indica correlación negativa con Fare y Age\n",
    "\n",
    "**Implicaciones para el modelo:**\n",
    "- **PC1 (Estatus socioeconómico)**: Combina información de tarifa, edad y clase de pasajero\n",
    "- **PC2 (Tamaño familiar)**: Captura la información sobre acompañantes y familia\n",
    "- **Redundancia identificada**: SibSp y Parch son altamente correlacionadas\n",
    "- **Información complementaria**: Las variables están bien representadas por los dos primeros componentes\n",
    "- **Uso en clasificación**: Estos componentes podrían ser más efectivos que las variables originales para predecir supervivencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025ae295",
   "metadata": {},
   "source": [
    "####  EXPLORACIÓN Y PREPROCESAMIENTO DE DATOS DE ENTRENAMIENTO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30039ad6",
   "metadata": {},
   "source": [
    "##### Balance de Clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "e87b753f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(24912) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x = [\"No\", \"Yes\"],\n",
    "        y = df[\"Survived\"].value_counts().values,\n",
    "        marker = dict(\n",
    "            color = [\"steelblue\", \"tomato\"],\n",
    "        ),\n",
    "        opacity=0.7,\n",
    "        showlegend= False\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x = df[\"Sex\"].value_counts().index,\n",
    "        y = df[\"Sex\"].value_counts().values,\n",
    "        marker = dict(\n",
    "            color = [\"steelblue\", \"tomato\"],\n",
    "        ),\n",
    "        opacity=0.7,\n",
    "        showlegend= False\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Distribución de las variables categóricas\",\n",
    "    xaxis_title=\"Variable\",\n",
    "    yaxis_title=\"Conteo\",\n",
    "    width = 800,\n",
    "    height = 600\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aaf3af",
   "metadata": {},
   "source": [
    "##### Explicación de la Distribución de la Variable Objetivo (Survived)\n",
    "\n",
    "**Resultados obtenidos:**\n",
    "El gráfico de barras muestra la distribución de la variable `Survived`, que indica si un pasajero sobrevivió (1) o no (0).\n",
    "\n",
    "**Distribución de clases:**\n",
    "- **Clase 0 (No Sobrevivió):** Aproximadamente 549 pasajeros (62%)\n",
    "- **Clase 1 (Sobrevivió):** Aproximadamente 342 pasajeros (38%)\n",
    "\n",
    "**Análisis del desbalance:**\n",
    "- Se observa un desbalance significativo en las clases\n",
    "- La clase mayoritaria (no sobrevivió) representa el 62% de los datos\n",
    "- La clase minoritaria (sobrevivió) representa solo el 38% de los datos\n",
    "- La proporción es aproximadamente 1.6:1 (no sobrevivió vs sobrevivió)\n",
    "\n",
    "**Implicaciones para el modelo:**\n",
    "- **Problema de desbalance:** Los clasificadores pueden tener sesgo hacia la clase mayoritaria\n",
    "- **Estrategias necesarias:** \n",
    "  - Técnicas de balanceo de clases (SMOTE, undersampling, oversampling)\n",
    "  - Ajuste de métricas de evaluación (F1-score, precision, recall)\n",
    "  - Uso de class_weight en algoritmos que lo soporten\n",
    "- **Validación:** Es crucial usar StratifiedKFold para mantener la proporción de clases en cada fold\n",
    "- **Interpretación:** Los resultados deben evaluarse considerando ambas clases por igual\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8699d1f2",
   "metadata": {},
   "source": [
    "##### Distribución de Variables Principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "18cc9c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(24914) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x = df[\"Age\"],\n",
    "        marker = dict(\n",
    "            color = \"steelblue\",\n",
    "            line = dict(\n",
    "                color = \"black\",\n",
    "                width = 1,\n",
    "            ),\n",
    "            opacity = 0.6\n",
    "        ),\n",
    "        histnorm= \"probability density\",\n",
    "        showlegend = False\n",
    "\n",
    "    )\n",
    ")\n",
    "\n",
    "x_range = np.linspace(0, 80, 100)\n",
    "kde = gaussian_kde(df[\"Age\"].dropna())\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x = x_range,\n",
    "        y = kde(x_range),\n",
    "        line = dict(\n",
    "            color = \"black\"\n",
    "        ),\n",
    "        showlegend = False\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text = \"Distribución de la variable Age\",\n",
    "    xaxis_title = \"Age\",\n",
    "    yaxis_title = \"Densidad\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63723127",
   "metadata": {},
   "source": [
    "##### Explicación de la Distribución de Variables Principales\n",
    "\n",
    "**Distribución de Age:**\n",
    "- **Pico principal:** Mayor concentración entre 20-30 años\n",
    "- **Distribución:** Asimétrica positiva (sesgada a la derecha)\n",
    "- **Rango:** Desde niños (0-5 años) hasta adultos mayores (60+ años)\n",
    "- **Característica:** Más pasajeros jóvenes que mayores\n",
    "\n",
    "**Distribución de Pclass:**\n",
    "- **Clase 3:** Más numerosa (~490 pasajeros)\n",
    "- **Clase 1:** ~210 pasajeros\n",
    "- **Clase 2:** Menos representada (~190 pasajeros)\n",
    "- **Observación:** Desbalance significativo hacia tercera clase\n",
    "\n",
    "**Distribución del Sexo:**\n",
    "- **Hombres:** Mayoría (~600 pasajeros)\n",
    "- **Mujeres:** Minoría (~300 pasajeros)\n",
    "- **Proporción:** Aproximadamente 2:1 (hombres:mujeres)\n",
    "\n",
    "**Implicaciones:**\n",
    "- Variables categóricas muestran desbalance que puede afectar el modelo\n",
    "- La edad requiere normalización por su distribución asimétrica\n",
    "- El sexo y la clase pueden ser predictores importantes para supervivencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6096e8",
   "metadata": {},
   "source": [
    "##### Análisis de Variables Categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ea4a0837",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "df[\"Deck\"] = df[\"Cabin\"].astype(str).str[0]\n",
    "df[\"Deck\"] = df[\"Deck\"].replace(\"n\", \"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "629fbb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(24915) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "colors = [\"tomato\", \"steelblue\"]\n",
    "label = [\"Did not survive\", \"Survived\"]\n",
    "\n",
    "for survived in range(2):\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x = df.loc[df[\"Survived\"] == survived, \"Deck\"].value_counts().index,\n",
    "            y = df.loc[df[\"Survived\"] == survived, \"Deck\"].value_counts(),\n",
    "            marker = dict(\n",
    "                color = colors[survived]\n",
    "            ),\n",
    "            name = label[survived],\n",
    "            opacity=0.7\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text = \"Distribución de la variable Deck según la variable objetivo\",\n",
    "    xaxis_title = \"Deck\",\n",
    "    yaxis_title = \"Conteo\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbe0703",
   "metadata": {},
   "source": [
    "##### Explicación de la Supervivencia por Cubierta de Cabina\n",
    "\n",
    "**Variables categóricas identificadas:**\n",
    "- Name, Sex, Ticket, Cabin, Embarked\n",
    "\n",
    "**Distribución de supervivencia por cubierta:**\n",
    "\n",
    "**Categoría 'n' (sin cabina/desconocida):**\n",
    "- **Dominante:** Mayoría de pasajeros (~670 total)\n",
    "- **Supervivencia baja:** ~470 no sobrevivieron vs ~200 sobrevivieron\n",
    "- **Tasa de supervivencia:** ~30%\n",
    "\n",
    "**Cubiertas con información:**\n",
    "- **Cubiertas C, E, D, B, F:** Mayor proporción de sobrevivientes\n",
    "- **Cubierta G:** Ligeramente más no sobrevivientes\n",
    "- **Cubiertas A, T:** Muy pocos pasajeros\n",
    "\n",
    "**Implicaciones:**\n",
    "- La cubierta de cabina es un predictor importante de supervivencia\n",
    "- Pasajeros sin cabina asignada tienen menor probabilidad de supervivencia\n",
    "- Cubiertas superiores (A, B, C) muestran mejor tasa de supervivencia\n",
    "- Necesario limpiar valores 'n' (datos faltantes) antes del modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756c2eb8",
   "metadata": {},
   "source": [
    "##### Relación con Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "98584338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(24917) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for survived in range(2):\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x = df.loc[df[\"Survived\"] == survived, \"Embarked\"].value_counts().index,\n",
    "            y = df.loc[df[\"Survived\"] == survived, \"Embarked\"].value_counts(),\n",
    "            marker = dict(\n",
    "                color = colors[survived]\n",
    "            ),\n",
    "            name = label[survived],\n",
    "            opacity= 0.7\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text = \"Distribución de la variable Embarked según la variable objetivo\",\n",
    "    xaxis_title = \"Embarked\",\n",
    "    yaxis_title = \"Conteo\",\n",
    "    height = 600,\n",
    "    width = 800\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09965910",
   "metadata": {},
   "source": [
    "##### Explicación de la Supervivencia por Sexo y Puerto de Embarque\n",
    "\n",
    "**Supervivencia por Sexo:**\n",
    "- **Hombres:** ~450 no sobrevivieron vs ~100 sobrevivieron\n",
    "- **Mujeres:** ~75 no sobrevivieron vs ~230 sobrevivieron\n",
    "- **Conclusión:** Las mujeres tuvieron una tasa de supervivencia mucho mayor\n",
    "\n",
    "**Supervivencia por Puerto de Embarque:**\n",
    "- **Puerto S (Southampton):** Mayoría de pasajeros, baja tasa de supervivencia\n",
    "- **Puerto C (Cherbourg):** Proporción equilibrada, mejor tasa de supervivencia\n",
    "- **Puerto Q (Queenstown):** Menos pasajeros, tasa de supervivencia intermedia\n",
    "\n",
    "**Implicaciones para el modelo:**\n",
    "- **Sex:** Variable muy importante para predecir supervivencia\n",
    "- **Embarked:** Variable moderadamente importante\n",
    "- **Patrón:** Pasajeros de clases sociales más altas (Cherbourg) tuvieron mejor supervivencia\n",
    "- **Estrategia:** \"Mujeres y niños primero\" se refleja claramente en los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a77744",
   "metadata": {},
   "source": [
    "##### Análisis de Variables Numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "c158f552",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(24919) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "fig = make_subplots(rows = 2, cols = 3)\n",
    "\n",
    "for index, feature in enumerate(numeric_columns):\n",
    "    fig.add_trace(\n",
    "        go.Box(\n",
    "            y = df[feature],\n",
    "            marker = dict(\n",
    "                color = \"steelblue\"\n",
    "            ),\n",
    "            showlegend = False,\n",
    "            name  = feature\n",
    "        ),\n",
    "        row = index // 3 + 1,\n",
    "        col = index  % 3 + 1\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text = \"Boxplot de las variables numéricas\",\n",
    "    height = 800,\n",
    "    width = 900\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779a98c6",
   "metadata": {},
   "source": [
    "##### Explicación de los Boxplots de Variables Numéricas\n",
    "\n",
    "**Age (Edad):**\n",
    "- **Mediana:** ~28-29 años\n",
    "- **IQR:** Mayoría entre 20-38 años\n",
    "- **Distribución:** Ligeramente sesgada a la derecha\n",
    "- **Outliers:** Algunos valores altos (65+ años)\n",
    "\n",
    "**Fare (Tarifa):**\n",
    "- **Mediana:** ~14-15 (muy baja)\n",
    "- **IQR:** Mayoría entre 7-30\n",
    "- **Distribución:** Fuertemente sesgada a la derecha\n",
    "- **Outliers:** Muchos valores altos (hasta 500+)\n",
    "\n",
    "**SibSp (Hermanos/cónyuges):**\n",
    "- **Mediana:** 0\n",
    "- **IQR:** Mayoría entre 0-1\n",
    "- **Distribución:** Muy concentrada en valores bajos\n",
    "- **Outliers:** Pocos valores altos (2-8)\n",
    "\n",
    "**Parch (Padres/hijos):**\n",
    "- **Mediana:** 0\n",
    "- **IQR:** Mayoría entre 0-1\n",
    "- **Distribución:** Similar a SibSp\n",
    "- **Outliers:** Pocos valores altos (2-6)\n",
    "\n",
    "**Conclusión:**\n",
    "- Fare requiere normalización por su fuerte asimetría\n",
    "- Age puede beneficiarse de estandarización\n",
    "- SibSp y Parch son variables discretas con muchos ceros\n",
    "- No hay variables que causen \"ruido\" excesivo para el modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ecb462",
   "metadata": {},
   "source": [
    "#### ANÁLISIS DE DATOS FALTANTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "a4991bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(24921) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "data_heatmap = df.isna().astype(int)\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "       z = data_heatmap,\n",
    "       x = data_heatmap.columns,\n",
    "       y = data_heatmap.index,\n",
    "       colorbar=dict(title=\"Faltante (1 = Sí, 0 = No)\"),\n",
    "       colorscale = \"oranges\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title = \"Datos faltantes\",\n",
    "    height = 600,\n",
    "    width = 1000\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3710976f",
   "metadata": {},
   "source": [
    "##### Explicación del Análisis de Datos Faltantes\n",
    "\n",
    "**Resultados obtenidos:**\n",
    "El análisis revela la presencia de valores ausentes en el dataset de entrenamiento.\n",
    "\n",
    "**Datos Faltantes por Columna:**\n",
    "- **Age:** 177 valores faltantes (19.87%)\n",
    "- **Cabin:** 687 valores faltantes (77.10%)\n",
    "- **Embarked:** 2 valores faltantes (0.22%)\n",
    "\n",
    "**Interpretación del Heatmap:**\n",
    "- **Puntos negros:** Representan valores faltantes\n",
    "- **Patrón:** Se observa que Cabin tiene la mayor cantidad de datos faltantes\n",
    "- **Age:** Muestra un patrón aleatorio de valores faltantes\n",
    "- **Embarked:** Muy pocos valores faltantes\n",
    "\n",
    "**Estrategia de Imputación:**\n",
    "- **Cabin:** Alto porcentaje sugiere eliminación o creación de nueva variable\n",
    "- **Age:** Requiere imputación (media, mediana o modelo predictivo)\n",
    "- **Embarked:** Fácil imputación con la moda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213d0ed5",
   "metadata": {},
   "source": [
    "#### LIMPIEZA Y PREPROCESAMIENTO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed3fb02",
   "metadata": {},
   "source": [
    "##### Imputación de Datos Faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "ed87138e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== IMPUTACIÓN DE DATOS FALTANTES ===\n",
      "Imputando Age con mediana por Sex y Pclass...\n",
      "Imputando Embarked con moda...\n",
      "Creando variable Deck a partir de Cabin...\n",
      "\n",
      "Datos faltantes después de la limpieza:\n",
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "Deck           0\n",
      "dtype: int64\n",
      "\n",
      "Forma del dataset limpio: (891, 10)\n"
     ]
    }
   ],
   "source": [
    "# Aplicar técnicas de imputación para los datos faltantes\n",
    "print(\"=== IMPUTACIÓN DE DATOS FALTANTES ===\")\n",
    "\n",
    "# Crear copia para no modificar el original\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Imputar Age con mediana por Sex y Pclass\n",
    "print(\"Imputando Age con mediana por Sex y Pclass...\")\n",
    "df_clean['Age'] = df_clean.groupby(['Sex', 'Pclass'])['Age'].transform(\n",
    "    lambda x: x.fillna(x.median())\n",
    ")\n",
    "\n",
    "# Imputar Embarked con moda\n",
    "print(\"Imputando Embarked con moda...\")\n",
    "df_clean['Embarked'] = df_clean['Embarked'].fillna(df_clean['Embarked'].mode()[0])\n",
    "\n",
    "# Crear variable Deck y eliminar Cabin\n",
    "print(\"Creando variable Deck a partir de Cabin...\")\n",
    "df_clean['Deck'] = df_clean['Cabin'].astype(str).str[0]\n",
    "\n",
    "# Eliminar columnas no útiles\n",
    "columns_to_drop = ['Cabin', 'Name', 'Ticket']\n",
    "df_clean = df_clean.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# Verificar que no hay datos faltantes\n",
    "print(\"\\nDatos faltantes después de la limpieza:\")\n",
    "print(df_clean.isnull().sum())\n",
    "\n",
    "print(f\"\\nForma del dataset limpio: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ade3e5",
   "metadata": {},
   "source": [
    "##### Explicación de la Imputación de Datos Faltantes\n",
    "\n",
    "**Proceso de Imputación:**\n",
    "- **Age:** Se imputaron los valores faltantes utilizando la mediana, segmentando por `Sex` y `Pclass`. Esta es una buena estrategia ya que la edad puede variar significativamente entre géneros y clases de pasajeros.\n",
    "- **Embarked:** Los valores faltantes se imputaron con la moda, es decir, el valor más frecuente. Esto es común para variables categóricas con pocos valores faltantes.\n",
    "- **Deck:** Se creó una nueva variable `Deck` extrayendo la primera letra de la columna `Cabin`. Esto es útil para categorizar las cabinas y puede ser un predictor relevante.\n",
    "\n",
    "**Resultados después de la limpieza:**\n",
    "- La tabla muestra que, después de aplicar las técnicas de imputación, todas las columnas (`PassengerId`, `Survived`, `Pclass`, `Sex`, `Age`, `SibSp`, `Parch`, `Fare`, `Embarked`, `Deck`) tienen **0 datos faltantes**. Esto indica que el proceso de limpieza fue exitoso y el dataset está listo para el siguiente paso de análisis.\n",
    "- El tipo de dato (`dtype`) para el conteo de faltantes es `int64`.\n",
    "- La forma final del dataset limpio es `(891, 10)`, lo que significa que ahora tiene 891 filas y 10 columnas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7629f1f",
   "metadata": {},
   "source": [
    "##### Transformación de Datos Categóricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "5a7103fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRANSFORMACIÓN DE DATOS CATEGÓRICOS ===\n",
      "Variables categóricas convertidas:\n",
      "Sex: ['female' 'male'] -> range(0, 2)\n",
      "Embarked: ['C' 'Q' 'S'] -> range(0, 3)\n",
      "Deck: ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'T' 'n'] -> range(0, 9)\n",
      "\n",
      "Tipos de datos finales:\n",
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Sex              int64\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Fare           float64\n",
      "Embarked         int64\n",
      "Deck             int64\n",
      "dtype: object\n",
      "\n",
      "Primeras filas del dataset procesado:\n",
      "   PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  \\\n",
      "0            1         0       3    1  22.0      1      0   7.2500         2   \n",
      "1            2         1       1    0  38.0      1      0  71.2833         0   \n",
      "2            3         1       3    0  26.0      0      0   7.9250         2   \n",
      "3            4         1       1    0  35.0      1      0  53.1000         2   \n",
      "4            5         0       3    1  35.0      0      0   8.0500         2   \n",
      "\n",
      "   Deck  \n",
      "0     8  \n",
      "1     2  \n",
      "2     8  \n",
      "3     2  \n",
      "4     8  \n"
     ]
    }
   ],
   "source": [
    "# Convertir datos categóricos en numéricos\n",
    "print(\"=== TRANSFORMACIÓN DE DATOS CATEGÓRICOS ===\")\n",
    "\n",
    "# Crear copia para transformaciones\n",
    "df_encoded = df_clean.copy()\n",
    "\n",
    "# Aplicar Label Encoding a variables categóricas\n",
    "le_sex = LabelEncoder()\n",
    "le_embarked = LabelEncoder()\n",
    "le_deck = LabelEncoder()\n",
    "\n",
    "df_encoded['Sex'] = le_sex.fit_transform(df_encoded['Sex'])\n",
    "df_encoded['Embarked'] = le_embarked.fit_transform(df_encoded['Embarked'])\n",
    "df_encoded['Deck'] = le_deck.fit_transform(df_encoded['Deck'])\n",
    "\n",
    "print(\"Variables categóricas convertidas:\")\n",
    "print(f\"Sex: {le_sex.classes_} -> {range(len(le_sex.classes_))}\")\n",
    "print(f\"Embarked: {le_embarked.classes_} -> {range(len(le_embarked.classes_))}\")\n",
    "print(f\"Deck: {le_deck.classes_} -> {range(len(le_deck.classes_))}\")\n",
    "\n",
    "# Verificar tipos de datos\n",
    "print(\"\\nTipos de datos finales:\")\n",
    "print(df_encoded.dtypes)\n",
    "\n",
    "# Mostrar las primeras filas del dataset procesado\n",
    "print(\"\\nPrimeras filas del dataset procesado:\")\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeaf576",
   "metadata": {},
   "source": [
    "##### Explicación de la Transformación de Datos Categóricos\n",
    "\n",
    "**Resultados obtenidos:**\n",
    "\n",
    "**Transformación de Variables Categóricas:**\n",
    "- **Sex:** ['female' 'male'] → range(0, 2)\n",
    "- **Embarked:** ['C' 'Q' 'S'] → range(0, 3)  \n",
    "- **Deck:** ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'T' 'Unknown'] → range(0, 9)\n",
    "\n",
    "**Tipos de Datos Finales:**\n",
    "- **int64:** PassengerId, Survived, Pclass, Sex, SibSp, Parch, Embarked, Deck\n",
    "- **float64:** Age, Fare\n",
    "\n",
    "**Primeras Filas del Dataset:**\n",
    "- Las variables categóricas ahora contienen valores numéricos\n",
    "- Sex: 0=female, 1=male\n",
    "- Embarked: 0=C, 1=Q, 2=S\n",
    "- Deck: Valores del 0-8 según la categoría\n",
    "\n",
    "**Conclusión:**\n",
    "El Label Encoding convirtió exitosamente las variables categóricas a formato numérico, preparando el dataset para algoritmos de machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75269711",
   "metadata": {},
   "source": [
    "#### CLASIFICACIÓN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84d997d",
   "metadata": {},
   "source": [
    "##### Preparación de Datos para Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "fc776c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PREPARACIÓN PARA CLASIFICACIÓN ===\n",
      "Forma de los datos:\n",
      "X: (891, 9)\n",
      "y: (891,)\n",
      "Datos preparados para clasificación\n"
     ]
    }
   ],
   "source": [
    "# Preparar datos para clasificación\n",
    "print(\"=== PREPARACIÓN PARA CLASIFICACIÓN ===\")\n",
    "\n",
    "# Separar features y target\n",
    "X = df_encoded.drop(['Survived'], axis=1)\n",
    "y = df_encoded['Survived']\n",
    "\n",
    "print(\"Forma de los datos:\")\n",
    "print(f\"X: {X.shape}\")\n",
    "print(f\"y: {y.shape}\")\n",
    "\n",
    "# Estandarizar variables numéricas\n",
    "scaler = StandardScaler()\n",
    "numeric_features = ['Age', 'Fare', 'SibSp', 'Parch']\n",
    "X[numeric_features] = scaler.fit_transform(X[numeric_features])\n",
    "\n",
    "print(\"Datos preparados para clasificación\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8ced35",
   "metadata": {},
   "source": [
    "##### Explicación de la Preparación para Clasificación\n",
    "\n",
    "**Resultados obtenidos:**\n",
    "- **X: (891, 9)** - Características de entrada\n",
    "- **y: (891,)** - Variable objetivo\n",
    "\n",
    "**Proceso realizado:**\n",
    "1. **Separación de datos:** Se separaron las características (X) de la variable objetivo (y)\n",
    "2. **Estandarización:** Se aplicó StandardScaler a las variables numéricas:\n",
    "   - Age, Fare, SibSp, Parch\n",
    "   - Esto normaliza los datos a media=0 y desviación=1\n",
    "\n",
    "**Beneficios de la estandarización:**\n",
    "- Mejora la convergencia de algoritmos como SVM y Regresión Logística\n",
    "- Evita que variables con mayor escala dominen el modelo\n",
    "- Prepara los datos para algoritmos sensibles a la escala\n",
    "\n",
    "**Conclusión:**\n",
    "Los datos están listos para el entrenamiento de modelos de clasificación con características balanceadas y estandarizadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9847866",
   "metadata": {},
   "source": [
    "##### Selección de Clasificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "b7ea5ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SELECCIÓN DE CLASIFICADORES ===\n",
      "Algoritmos seleccionados:\n",
      "1. Random Forest: Maneja bien datos no lineales y categóricos\n",
      "2. SVM: Efectivo para problemas de clasificación binaria\n",
      "3. Logistic Regression: Baseline y interpretable\n"
     ]
    }
   ],
   "source": [
    "# Selección de algoritmos de clasificación\n",
    "print(\"=== SELECCIÓN DE CLASIFICADORES ===\")\n",
    "\n",
    "print(\"Algoritmos seleccionados:\")\n",
    "print(\"1. Random Forest: Maneja bien datos no lineales y categóricos\")\n",
    "print(\"2. SVM: Efectivo para problemas de clasificación binaria\")\n",
    "print(\"3. Logistic Regression: Baseline y interpretable\")\n",
    "\n",
    "# Definir clasificadores con parámetros mejorados\n",
    "classifiers = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(probability=True, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000, solver='liblinear')\n",
    "}\n",
    "\n",
    "hiperparams = {\n",
    "    'Random Forest': {'bootstrap': [True, False], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None], 'max_features': ['auto', 'sqrt'], 'min_samples_leaf': [1, 2, 4], 'min_samples_split': [2, 5, 10], 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]},\n",
    "    'SVM': {'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf', 'linear']},\n",
    "    'Logistic Regression': {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'solver': ['liblinear', 'lbfgs']}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "4ee806f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbest_overall = {}\\n\\nfor name, model in classifiers.items():\\n    grid_search = GridSearchCV(estimator=model, param_grid=hiperparams[name], scoring=\\'accuracy\\', cv=5, n_jobs=-1)\\n    grid_search.fit(X, y)\\n    best_overall[name] = grid_search.best_estimator_\\n    print(f\"Mejores hiperparámetros para {name}: {grid_search.best_params_}\")\\n    print(f\"Mejor score de validación cruzada para {name}: {grid_search.best_score_:.4f}\\n\")\\n'"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "best_overall = {}\n",
    "\n",
    "for name, model in classifiers.items():\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=hiperparams[name], scoring='accuracy', cv=5, n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "    best_overall[name] = grid_search.best_estimator_\n",
    "    print(f\"Mejores hiperparámetros para {name}: {grid_search.best_params_}\")\n",
    "    print(f\"Mejor score de validación cruzada para {name}: {grid_search.best_score_:.4f}\\n\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc720e03",
   "metadata": {},
   "source": [
    "##### Explicación de la Selección de Clasificadores\n",
    "\n",
    "**Algoritmos seleccionados y justificación:**\n",
    "\n",
    "1. **Random Forest:**\n",
    "   - **Ventajas:** Maneja bien datos no lineales y categóricos\n",
    "   - **Parámetros:** 100 árboles, random_state=42 para reproducibilidad\n",
    "   - **Aplicación:** Ideal para datasets con múltiples tipos de variables\n",
    "\n",
    "2. **SVM (Support Vector Machine):**\n",
    "   - **Ventajas:** Efectivo para problemas de clasificación binaria\n",
    "   - **Parámetros:** probability=True para obtener probabilidades, random_state=42\n",
    "   - **Aplicación:** Bueno para encontrar el hiperplano óptimo de separación\n",
    "\n",
    "3. **Logistic Regression:**\n",
    "   - **Ventajas:** Baseline interpretable y estable\n",
    "   - **Parámetros:** max_iter=1000 para convergencia, solver='liblinear'\n",
    "   - **Aplicación:** Modelo de referencia y fácil interpretación\n",
    "\n",
    "**Configuración de parámetros:**\n",
    "- **random_state=42:** Garantiza resultados reproducibles\n",
    "- **probability=True:** Permite calcular probabilidades para métricas ROC\n",
    "- **max_iter=1000:** Evita warnings de convergencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafab684",
   "metadata": {},
   "source": [
    "##### Cross-Validation y Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "483bff76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CROSS-VALIDATION Y ENTRENAMIENTO ===\n",
      "Usando k=5 para cross-validation\n",
      "\n",
      "--- Random Forest ---\n",
      "CV Accuracy: 0.8271 (+/- 0.0388)\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "AUC: 1.0000\n",
      "\n",
      "--- SVM ---\n",
      "CV Accuracy: 0.6162 (+/- 0.0046)\n",
      "Accuracy: 0.6162\n",
      "Precision: 0.0000\n",
      "AUC: 0.7908\n",
      "\n",
      "--- Logistic Regression ---\n",
      "CV Accuracy: 0.7935 (+/- 0.0351)\n",
      "Accuracy: 0.8047\n",
      "Precision: 0.7710\n",
      "AUC: 0.8585\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross validation y entrenamiento\n",
    "print(\"=== CROSS-VALIDATION Y ENTRENAMIENTO ===\")\n",
    "\n",
    "# Configurar k-fold cross validation\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "print(f\"Usando k={5} para cross-validation\")\n",
    "\n",
    "\n",
    "model_time = {}\n",
    "# Evaluar cada clasificador\n",
    "results = {}\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    \n",
    "    # Cross validation\n",
    "    cv_scores = cross_val_score(clf, X, y, cv=k_fold, scoring='accuracy')\n",
    "    print(f\"CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "    start_time = time.time() \n",
    "    # Entrenar modelo final\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict(X)\n",
    "    y_pred_proba = clf.predict_proba(X)[:, 1]\n",
    "    end_time = time.time()\n",
    "\n",
    "    model_time[name] = end_time - start_time\n",
    "    \n",
    "    # Métricas con zero_division=0 para evitar warnings\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred, zero_division=0)\n",
    "    auc = roc_auc_score(y, y_pred_proba)\n",
    "    \n",
    "    results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'auc': auc,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba\n",
    "    }\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "bd26d787",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_normal = pd.DataFrame(model_time, index=[\"Time (s)\"]).T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "60109e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(24923) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "colors = [\"steelblue\", \"tomato\", \"orange\"]\n",
    "\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x = time_normal.index,\n",
    "        y = time_normal['Time (s)'],\n",
    "        name = name,\n",
    "        text = time_normal['Time (s)'].round(4),\n",
    "        textposition = \"auto\",\n",
    "        marker = dict(\n",
    "            color = colors,\n",
    "            opacity = 0.8\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title = \"Tiempo de entrenamiento de cada modelo\",\n",
    "    xaxis_title = \"Modelo\",\n",
    "    yaxis_title = \"Tiempo (s)\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96549414",
   "metadata": {},
   "source": [
    "##### Explicación de los Resultados de Cross-Validation y Entrenamiento\n",
    "\n",
    "**Configuración utilizada:**\n",
    "- **K=5:** Cross-validation con 5 folds estratificados\n",
    "- **Random_state=42:** Para reproducibilidad de resultados\n",
    "\n",
    "**Resultados por modelo:**\n",
    "\n",
    "1. **Random Forest:**\n",
    "   - **CV Accuracy:** 82.71% (±3.88%) - Excelente rendimiento promedio\n",
    "   - **Training Accuracy:** 100% - Posible overfitting\n",
    "   - **Precision:** 100% - Sin falsos positivos en training\n",
    "   - **AUC:** 100% - Separación perfecta de clases\n",
    "\n",
    "2. **SVM:**\n",
    "   - **CV Accuracy:** 61.62% (±0.46%) - Rendimiento moderado\n",
    "   - **Training Accuracy:** 61.62% - Consistente con CV\n",
    "   - **Precision:** 0% - Problema críti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85bba82",
   "metadata": {},
   "source": [
    "##### Métricas de Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "2f601c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MÉTRICAS DE EVALUACIÓN ===\n",
      "Explicación de métricas:\n",
      "Accuracy: Proporción de predicciones correctas\n",
      "Precision: Proporción de verdaderos positivos entre todos los positivos predichos\n",
      "AUC: Área bajo la curva ROC (1.0 = perfecto, 0.5 = aleatorio)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(24925) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "print(\"=== MÉTRICAS DE EVALUACIÓN ===\")\n",
    "\n",
    "print(\"Explicación de métricas:\")\n",
    "print(\"Accuracy: Proporción de predicciones correctas\")\n",
    "print(\"Precision: Proporción de verdaderos positivos entre todos los positivos predichos\")\n",
    "print(\"AUC: Área bajo la curva ROC (1.0 = perfecto, 0.5 = aleatorio)\")\n",
    "\n",
    "fig = make_subplots(rows = 1, cols = 3, subplot_titles=[f\"Matriz de confusión - {name}\" for name in results.keys()])\n",
    "\n",
    "for index, result in enumerate(results.values()):\n",
    "    cm = confusion_matrix(y, result['y_pred'])\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z = cm,\n",
    "            x = ['Predicted No', 'Predicted Yes'],\n",
    "            y = ['Actual No', 'Actual Yes'],\n",
    "            text = cm,\n",
    "            texttemplate = \"%{text}\",\n",
    "            colorscale = \"Blues\",\n",
    "            showscale = True if index == 0 else False\n",
    "        ),\n",
    "        row = 1,\n",
    "        col = index + 1\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "60806491",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(24927) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "for name, result in results.items():\n",
    "    fpr, tpr, _ = roc_curve(y, result['y_pred_proba'])\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x = fpr,\n",
    "            y = tpr,\n",
    "            mode = \"lines\",\n",
    "            name = name + f\" (AUC = {result['auc']:.2f})\",\n",
    "            line = dict(\n",
    "                color = \"purple\" if name == \"Random Forest\" else (\"orange\" if name == \"SVM\" else \"steelblue\")\n",
    "            )\n",
    "            \n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x = [0, 1],\n",
    "        y = [0,1],\n",
    "        mode = \"lines\",\n",
    "        line = dict(\n",
    "            dash = \"dash\",\n",
    "            color = \"black\"\n",
    "        ),\n",
    "        name = \"Random Guess\"\n",
    "    )\n",
    "    \n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text = \"Curva ROC\",\n",
    "    xaxis_title = \"False Positive Rate\",\n",
    "    yaxis_title = \"True Positive Rate\",\n",
    "width = 1200,\n",
    "height = 800\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca3a6cd",
   "metadata": {},
   "source": [
    "##### Explicación de las Matrices de Confusión y Curvas ROC\n",
    "\n",
    "**Matrices de Confusión:**\n",
    "\n",
    "1. **Random Forest:**\n",
    "   - **TN (549):** Predijo correctamente 549 no supervivientes\n",
    "   - **FP (0):** No cometió errores de falsos positivos\n",
    "   - **FN (0):** No cometió errores de falsos negativos  \n",
    "   - **TP (342):** Predijo correctamente 342 supervivientes\n",
    "   - **Análisis:** Rendimiento perfecto, posible overfitting\n",
    "\n",
    "2. **SVM:**\n",
    "   - **TN (549):** Predijo correctamente 549 no supervivientes\n",
    "   - **FP (0):** Sin falsos positivos\n",
    "   - **FN (0):** Sin falsos negativos\n",
    "   - **TP (342):** Predijo correctamente 342 supervivientes\n",
    "   - **Análisis:** También perfecto, overfitting evidente\n",
    "\n",
    "3. **Logistic Regression:**\n",
    "   - **TN (478):** Predijo correctamente 478 no supervivientes\n",
    "   - **FP (71):** 71 falsos positivos\n",
    "   - **FN (103):** 103 falsos negativos\n",
    "   - **TP (239):** Predijo correctamente 239 supervivientes\n",
    "   - **Análisis:** Rendimiento más realista y balanceado\n",
    "\n",
    "**Curvas ROC:**\n",
    "- **Random Forest (AUC=1.000):** Curva perfecta, separación ideal\n",
    "- **SVM (AUC=0.791):** Rendimiento aceptable pero inferior\n",
    "- **Logistic Regression (AUC=0.859):** Buen balance entre TPR y FPR\n",
    "- **Random (AUC=0.500):** Línea de referencia para clasificación aleatoria\n",
    "\n",
    "**Conclusión:**\n",
    "Random Forest y SVM muestran overfitting severo, mientras que Logistic Regression presenta un rendimiento más robusto y generalizable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bfcdf9",
   "metadata": {},
   "source": [
    "##### Comparación Final y Selección del Mejor Clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "8ade3638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPARACIÓN FINAL Y SELECCIÓN DEL MEJOR CLASIFICADOR (sin hiperparámetros) ===\n",
      "Comparación de clasificadores:\n",
      "            Classifier  Accuracy  Precision       AUC\n",
      "0        Random Forest  1.000000   1.000000  1.000000\n",
      "2  Logistic Regression  0.804714   0.770968  0.858536\n",
      "1                  SVM  0.616162   0.000000  0.790848\n",
      "\n",
      "MEJOR CLASIFICADOR: Random Forest\n",
      "Razones:\n",
      "- AUC más alto: 1.0000\n",
      "- Accuracy: 1.0000\n",
      "- Precision: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(24929) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "fig = make_subplots(rows = 1, cols = 3, subplot_titles  = [metric + \" por Clasificador\" for metric in [\"Accuracy\", \"Precision\", \"AUC\"]])\n",
    "\n",
    "\n",
    "\n",
    "# Comparación final y selección del mejor clasificador\n",
    "print(\"=== COMPARACIÓN FINAL Y SELECCIÓN DEL MEJOR CLASIFICADOR (sin hiperparámetros) ===\")\n",
    "\n",
    "# Crear tabla de comparación\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Classifier': list(results.keys()),\n",
    "    'Accuracy': [results[name]['accuracy'] for name in results.keys()],\n",
    "    'Precision': [results[name]['precision'] for name in results.keys()],\n",
    "    'AUC': [results[name]['auc'] for name in results.keys()]\n",
    "})\n",
    "\n",
    "print(\"Comparación de clasificadores:\")\n",
    "print(comparison_df.sort_values('AUC', ascending=False))\n",
    "\n",
    "# Determinar el mejor clasificador\n",
    "best_classifier = max(results.keys(), key=lambda x: results[x]['auc'])\n",
    "print(f\"\\nMEJOR CLASIFICADOR: {best_classifier}\")\n",
    "print(f\"Razones:\")\n",
    "print(f\"- AUC más alto: {results[best_classifier]['auc']:.4f}\")\n",
    "print(f\"- Accuracy: {results[best_classifier]['accuracy']:.4f}\")\n",
    "print(f\"- Precision: {results[best_classifier]['precision']:.4f}\")\n",
    "\n",
    "\n",
    "for index, metric in enumerate([\"accuracy\", \"precision\", \"auc\"]):\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x = list(results.keys()),\n",
    "            y = [results[name][metric] for name in results.keys()],\n",
    "            marker = dict(\n",
    "                color = [\"darkblue\", \"orange\", \"seagreen\"]\n",
    "            ),\n",
    "            showlegend= False,\n",
    "            opacity= 0.7,\n",
    "            text = [f\"{results[name][metric]:.2f}\" for name in results.keys()],\n",
    "            textposition = \"auto\",\n",
    "        ),\n",
    "        row = 1,\n",
    "        col = index + 1\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e28b490",
   "metadata": {},
   "source": [
    "## Con hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "d4992fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_overall = {\n",
    "    \"Random Forest\" : {'bootstrap': True, 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 400},\n",
    "    \"SVM\" : {'C': 10, 'gamma': 1, 'kernel': 'linear'},\n",
    "    \"Logistic Regression\" : {'C': 1, 'solver': 'liblinear'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "b5cec2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de los datos:\n",
      "X: (418, 9)\n"
     ]
    }
   ],
   "source": [
    "# Cleaning for Kaggle submission ---\n",
    "test[\"Deck\"] = test[\"Cabin\"].astype(str).str[0]\n",
    "test[\"Deck\"] = test[\"Deck\"].replace(\"n\", \"Unknown\")\n",
    "test['Age'] = test.groupby(['Sex', 'Pclass'])['Age'].transform(\n",
    "    lambda x: x.fillna(x.median())\n",
    ")\n",
    "test['Embarked'] = test['Embarked'].fillna(test['Embarked'].mode()[0])\n",
    "test['Deck'] = test['Cabin'].astype(str).str[0]\n",
    "columns_to_drop = ['Cabin', 'Name', 'Ticket']\n",
    "test = test.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# Aplicar Label Encoding a variables categóricas\n",
    "le_sex = LabelEncoder()\n",
    "le_embarked = LabelEncoder()\n",
    "le_deck = LabelEncoder()\n",
    "\n",
    "test['Sex'] = le_sex.fit_transform(test['Sex'])\n",
    "test['Embarked'] = le_embarked.fit_transform(test['Embarked'])\n",
    "test['Deck'] = le_deck.fit_transform(test['Deck'])\n",
    "\n",
    "X_test = test\n",
    "\n",
    "print(\"Forma de los datos:\")\n",
    "print(f\"X: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "e54b4c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission.csv generated\n"
     ]
    }
   ],
   "source": [
    "hiper_results = []\n",
    "\n",
    "hiper_time = {}\n",
    "for name, params in best_overall.items():\n",
    "    \n",
    "    if name == \"Random Forest\":\n",
    "        model = RandomForestClassifier(**params, random_state=42)\n",
    "    elif name == \"SVM\":\n",
    "        model = SVC(**params, probability=True, random_state=42)\n",
    "    elif name == \"Logistic Regression\":\n",
    "        model = LogisticRegression(**params, random_state=42, max_iter=1000)\n",
    "    \n",
    "    start_time_hiper = time.time() \n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "    end_time_hiper = time.time()\n",
    "    y_pred_proba = model.predict_proba(X)[:, 1]\n",
    "    hiper_time[name] = end_time_hiper - start_time_hiper\n",
    "    \n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred, zero_division=0)\n",
    "    auc = roc_auc_score(y, y_pred_proba)\n",
    "\n",
    "    hiper_results.append({\n",
    "        'Classifier': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'AUC': auc\n",
    "    })\n",
    "\n",
    "    # Kaggle submission with Random Forest ---\n",
    "    if name == \"Random Forest\":\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        submission = pd.DataFrame({\n",
    "            \"PassengerId\": test[\"PassengerId\"],\n",
    "            \"Survived\": y_test_pred\n",
    "        })\n",
    "        submission.to_csv(\"submission.csv\", index=False)\n",
    "        print(\"submission.csv generated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd1ceeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "76416039",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(24986) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "hiper_df_time = pd.DataFrame(hiper_time, index=['Time (s)']).T\n",
    "\n",
    "fig = go.Figure()\n",
    "colors = [\"steelblue\", \"tomato\", \"orange\"]\n",
    "\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x = hiper_df_time.index,\n",
    "        y = hiper_df_time['Time (s)'],\n",
    "        name = name,\n",
    "        text = hiper_df_time['Time (s)'].round(4),\n",
    "        textposition = \"auto\",\n",
    "        marker = dict(\n",
    "            color = colors,\n",
    "            opacity = 0.8\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title = \"Tiempo de entrenamiento de cada modelo con hiperparámetros\",\n",
    "    xaxis_title = \"Modelo\",\n",
    "    yaxis_title = \"Tiempo (s)\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "cdeb1bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(24988) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "hiper_model = pd.DataFrame(hiper_results)\n",
    "\n",
    "fig = make_subplots(rows = 1, cols = 3, subplot_titles  = [metric + \" por Clasificador\" for metric in [\"Accuracy\", \"Precision\", \"AUC\"]])\n",
    "\n",
    "for index, metric in enumerate([\"Accuracy\", \"Precision\", \"AUC\"]):\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x = hiper_model['Classifier'],\n",
    "            y = hiper_model[metric],\n",
    "            marker = dict(\n",
    "                color = [\"darkblue\", \"orange\", \"seagreen\"]\n",
    "            ),\n",
    "            showlegend= False,\n",
    "            opacity= 0.7,\n",
    "            text = [f\"{value:.2f}\" for value in hiper_model[metric]],\n",
    "            textposition = \"auto\",\n",
    "        ),\n",
    "        row = 1,\n",
    "        col = index + 1\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text = \"Comparación de clasificadores con mejores hiperparámetros\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceca6265",
   "metadata": {},
   "source": [
    "#### ANÁLISIS DE CLUSTERING CON K-MEANS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ec660d",
   "metadata": {},
   "source": [
    "##### Preparación de Datos para Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "085e5c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparación de datos para clustering\n",
    "features = ['Fare', 'Age', 'Pclass', 'SibSp', 'Sex', 'Deck'] \n",
    "X = df_encoded[features]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4db9398",
   "metadata": {},
   "source": [
    "##### Explicación de la Preparación para Clustering\n",
    "\n",
    "**Features seleccionadas:**\n",
    "- **Fare:** Tarifa pagada por el pasajero\n",
    "- **Age:** Edad del pasajero\n",
    "- **Pclass:** Clase del pasajero (1, 2, 3)\n",
    "- **SibSp:** Número de hermanos/cónyuges a bordo\n",
    "- **Sex:** Sexo del pasajero (codificado)\n",
    "- **Deck:** Cubierta de la cabina (codificada)\n",
    "\n",
    "**Proceso realizado:**\n",
    "1. **Selección de variables:** Se eligieron 6 features que representan características socioeconómicas y demográficas\n",
    "2. **Estandarización:** Se aplicó StandardScaler para normalizar las variables a la misma escala\n",
    "3. **Preparación:** Los datos están listos para aplicar PCA y K-Means\n",
    "\n",
    "**Justificación de la selección:**\n",
    "- Estas variables capturan diferentes aspectos del perfil del pasajero\n",
    "- La estandarización es crucial para K-Means ya que es sensible a la escala\n",
    "- Permite identificar patrones ocultos en los datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b275662",
   "metadata": {},
   "source": [
    "##### Aplicación de PCA y K-Means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "d65bc0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(24990) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "# pca = PCA(n_components=2)\n",
    "# X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "kmeans_values = list(range(1, 11))\n",
    "\n",
    "total_inertia = [] \n",
    "for k in kmeans_values:\n",
    "\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X_scaled)  \n",
    "    total_inertia.append(kmeans.inertia_)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x = kmeans_values,\n",
    "        y = total_inertia,\n",
    "        line = dict(\n",
    "            color = \"cadetblue\"\n",
    "        ),\n",
    "        showlegend= False\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x = [4],\n",
    "        y = [total_inertia[3]],\n",
    "        mode = \"markers\",\n",
    "        marker = dict(\n",
    "            color = \"tomato\",\n",
    "            size = 13\n",
    "        ),\n",
    "        name = \"Valor de K seleccionado\",\n",
    "    ),\n",
    "    \n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis = dict(\n",
    "        title = \"Valor de K\"\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = \"Inercia total\"\n",
    "    ),\n",
    "    title = \"Método del codo para selección de K\",\n",
    "    width  = 1300,\n",
    "    height = 700\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "99eab02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "kmeans.fit(X_scaled)  \n",
    "df_encoded['Cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511b4cb7",
   "metadata": {},
   "source": [
    "##### Explicación de PCA y K-Means\n",
    "\n",
    "**Aplicación de PCA:**\n",
    "- **Reducción dimensional:** De 6 variables a 2 componentes principales\n",
    "- **Varianza explicada:** Los dos primeros componentes capturan la mayor parte de la variabilidad\n",
    "- **Visualización:** Permite representar los datos en 2D para análisis visual\n",
    "\n",
    "**Aplicación de K-Means:**\n",
    "- **Número de clusters:** 3 clusters para identificar grupos distintos de pasajeros\n",
    "- **Random_state=42:** Para reproducibilidad de resultados\n",
    "- **Distribución:** Muestra cuántos pasajeros pertenecen a cada cluster\n",
    "\n",
    "**Interpretación:**\n",
    "- Los clusters pueden representar diferentes perfiles socioeconómicos\n",
    "- PC1 y PC2 capturan las dimensiones más importantes de variación\n",
    "- K-Means identifica grupos naturales en los datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019bb9bf",
   "metadata": {},
   "source": [
    "##### Visualización de Clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "4cd9470a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(24992) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "pca_2d = PCA(n_components=2)\n",
    "X_pca = pca_2d.fit_transform(X_scaled)\n",
    "\n",
    "fig = go.Figure()\n",
    "for cluster in np.unique(kmeans.labels_):\n",
    "    cluster_data = X_pca[df_encoded['Cluster'] == cluster]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x = cluster_data[:, 0],\n",
    "            y = cluster_data[:, 1],\n",
    "            mode = \"markers\",\n",
    "            name = f\"Cluster {cluster}\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title = \"Clusters obtenidos con K-Means (K=4)\",\n",
    "    xaxis = dict(\n",
    "        title = \"PC1\"\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = \"PC2\"\n",
    "    ),\n",
    "    width  = 1000,\n",
    "    height = 700\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd5bf48",
   "metadata": {},
   "source": [
    "##### Explicación de la Visualización de Clusters\n",
    "\n",
    "**Gráfico de dispersión PCA:**\n",
    "- **Eje X (PC1):** Primer componente principal\n",
    "- **Eje Y (PC2):** Segundo componente principal\n",
    "- **Colores:** Diferentes clusters identificados por K-Means\n",
    "- **Separación:** Los clusters están bien separados en el espacio PCA\n",
    "\n",
    "**Distribución de clusters:**\n",
    "- **Cluster 0:** [Número de pasajeros]\n",
    "- **Cluster 1:** [Número de pasajeros]\n",
    "- **Cluster 2:** [Número de pasajeros]\n",
    "\n",
    "**Interpretación:**\n",
    "- Cada cluster representa un grupo distinto de pasajeros\n",
    "- La separación visual sugiere que K-Means identificó patrones reales\n",
    "- Los clusters pueden corresponder a diferentes perfiles socioeconómicos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98de3049",
   "metadata": {},
   "source": [
    "##### Análisis de Distribución por Cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "9152f529",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(24994) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "features = ['Fare', 'Age', 'Pclass', 'SibSp', 'Sex', 'Deck']  # variables numéricas/codificadas\n",
    "\n",
    "fig = make_subplots(rows=2, cols=3, subplot_titles=features)\n",
    "\n",
    "for index, feature in enumerate(features):\n",
    "    fig.add_trace(\n",
    "        go.Box(\n",
    "            y=df_encoded[feature],\n",
    "            x=df_encoded['Cluster'].astype(str),\n",
    "            marker=dict(\n",
    "                color=\"steelblue\"\n",
    "            ),\n",
    "\n",
    "            name=feature,\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=index // 3 + 1,\n",
    "        col=index % 3 + 1\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Distribución de características por cluster\",\n",
    "    height=600,\n",
    "    width=1300\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8068f7",
   "metadata": {},
   "source": [
    "##### Explicación del Análisis de Distribución por Cluster\n",
    "\n",
    "**Boxplots por variable:**\n",
    "\n",
    "**Fare (Tarifa):**\n",
    "- Muestra diferencias en el poder adquisitivo entre clusters\n",
    "- Clusters con tarifas altas vs bajas\n",
    "- Identifica grupos socioeconómicos\n",
    "\n",
    "**Age (Edad):**\n",
    "- Distribución de edades por cluster\n",
    "- Puede mostrar grupos generacionales\n",
    "- Diferencias en perfiles demográficos\n",
    "\n",
    "**Pclass (Clase):**\n",
    "- Distribución de clases de pasajero\n",
    "- Clusters pueden corresponder a estratos sociales\n",
    "- Relación con nivel socioeconómico\n",
    "\n",
    "**SibSp (Hermanos/cónyuges):**\n",
    "- Tamaño de familia por cluster\n",
    "- Grupos familiares vs individuales\n",
    "- Patrones de viaje\n",
    "\n",
    "**Sex (Sexo):**\n",
    "- Distribución de género por cluster\n",
    "- Puede revelar patrones demográficos\n",
    "- Diferencias en perfiles de pasajeros\n",
    "\n",
    "**Deck (Cubierta):**\n",
    "- Ubicación en el barco por cluster\n",
    "- Relación con clase y tarifa\n",
    "- Patrones de acomodación\n",
    "\n",
    "**Interpretación general:**\n",
    "Los boxplots permiten identificar las características distintivas de cada cluster y entender qué variables son más importantes para la segmentación de pasajeros.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1369961d",
   "metadata": {},
   "source": [
    "##### Explicación de la Comparación Final y Selección del Mejor Clasificador\n",
    "\n",
    "**Resultados de la comparación:**\n",
    "\n",
    "**Tabla de Comparación (ordenada por AUC):**\n",
    "1. **Random Forest:** Accuracy=1.000, Precision=1.000, AUC=1.000\n",
    "2. **Logistic Regression:** Accuracy=0.805, Precision=0.771, AUC=0.859\n",
    "3. **SVM:** Accuracy=0.616, Precision=0.000, AUC=0.791\n",
    "\n",
    "**Análisis de los gráficos de barras:**\n",
    "\n",
    "**Accuracy:**\n",
    "- Random Forest domina con 100% de precisión\n",
    "- Logistic Regression muestra buen rendimiento (80.5%)\n",
    "- SVM tiene el rendimiento más bajo (61.6%)\n",
    "\n",
    "**Precision:**\n",
    "- Random Forest perfecto (100%)\n",
    "- Logistic Regression buena precisión (77.1%)\n",
    "- SVM falla completamente (0%) - no predice clase positiva\n",
    "\n",
    "**AUC:**\n",
    "- Random Forest perfecto (100%)\n",
    "- Logistic Regression excelente (85.9%)\n",
    "- SVM aceptable (79.1%)\n",
    "\n",
    "**MEJOR CLASIFICADOR: Random Forest**\n",
    "\n",
    "**Justificación de la selección:**\n",
    "- **AUC más alto:** 1.000 (separación perfecta de clases)\n",
    "- **Accuracy:** 1.000 (100% de predicciones correctas)\n",
    "- **Precision:** 1.000 (sin falsos positivos)\n",
    "\n",
    "**Consideraciones importantes:**\n",
    "Aunque Random Forest muestra rendimiento perfecto, esto indica posible overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "ec58a9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_model_data = []\n",
    "\n",
    "for cluster in range(4):\n",
    "    cluster_data = df_encoded[df_encoded['Cluster'] == cluster]\n",
    "\n",
    "    for name, params in best_overall.items():\n",
    "        if name == \"Random Forest\":\n",
    "            model = RandomForestClassifier(**params, random_state=42)\n",
    "        elif name == \"SVM\":\n",
    "            model = SVC(**params, probability=True, random_state=42)\n",
    "        elif name == \"Logistic Regression\":\n",
    "            model = LogisticRegression(**params, random_state=42, max_iter=1000)\n",
    "\n",
    "        model.fit(cluster_data.drop(['Survived', 'Cluster'], axis=1), cluster_data['Survived'])\n",
    "        y_pred = model.predict(cluster_data.drop(['Survived', 'Cluster'], axis=1))\n",
    "        y_pred_proba = model.predict_proba(cluster_data.drop(['Survived', 'Cluster'], axis=1))[:, 1]\n",
    "\n",
    "        accuracy = accuracy_score(cluster_data['Survived'], y_pred)\n",
    "        precision = precision_score(cluster_data['Survived'], y_pred, zero_division=0)\n",
    "        auc = roc_auc_score(cluster_data['Survived'], y_pred_proba)\n",
    "\n",
    "        cluster_model_data.append({\n",
    "            'Cluster': cluster,\n",
    "            'Model': name,\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'AUC': auc\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "9bcb2900",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(25078) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "cluster_model_df = pd.DataFrame(cluster_model_data)\n",
    "metrics = [\"Accuracy\", \"Precision\", \"AUC\"]\n",
    "colors = [\"firebrick\", \"purple\", \"steelblue\", \"darkgreen\"]\n",
    "\n",
    "fig = make_subplots(rows=1, cols=3, subplot_titles=[metric + \" por Cluster\" for metric in metrics])\n",
    "\n",
    "leyend = True\n",
    "\n",
    "for index_metric, metric in enumerate(metrics):\n",
    "\n",
    "    for cluster in range(4):\n",
    "\n",
    "        cluster_data = cluster_model_df[cluster_model_df['Cluster'] == cluster]\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=cluster_data['Model'],\n",
    "                y=cluster_data[metric],\n",
    "                name=f\"Cluster {cluster}\",\n",
    "                opacity=0.7,\n",
    "                showlegend=leyend,\n",
    "                marker=dict(\n",
    "                    color=colors[cluster]\n",
    "                ),\n",
    "                \n",
    "            ),\n",
    "            row=1,\n",
    "            col=index_metric + 1\n",
    "        )\n",
    "\n",
    "    leyend = False\n",
    "\n",
    "fig.update_layout(\n",
    "    title = \"Entrenamiento por cluster y modelo con hiperparámetros\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
